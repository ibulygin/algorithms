# Grokking Algorithms

![Grokking Algorithms](thumb.jpg)

## Шпаргалка

<details>
  <summary>Знакомство с алгоритмами</summary>

* Бинарный поиск работает намного быстрее простого.
* Время выполнения O(log п) быстрее О(п), а с увеличением размера списка, в котором ищется значение, оно становится намного быстрее.
* Скорость алгоритмов не измеряется в секундах.
* Время выполнения алгоритма описывается ростом количества операций.
* Время выполнения алгоритмов выражается как «О-большое~. 
</details>

<details>
  <summary>Сортировка выбором</summary>

* Память компьютера напоминает огромный шкаф с ящиками.
* Если вам потребуется сохранить набор элементов, воспользуйтесь массивом или списком.
* В массиве все элементы хранятся в памяти рядом друг с другом.
* В списке элементы распределяются в произвольных местах памяти, при этом в одном элементе хранится адрес следующего элемента.
* Массивы обеспечивают быстрое чтение.
* Списки обеспечивают быструю вставку и выполнение.
* Все элементы массива должны быть однотипными (только целые числа, только вещественные числа и т. д.). 
</details>

<details>
  <summary>Рекурсия</summary>

* Когда функция вызывает саму себя, это называется рекурсией.
* В каждой рекурсивной функции должно быть два случая: базовый и рекурсивный.
* Стек поддерживает две операции: занесение и извлечение элементов.
* Все вызовы функций сохраняются в стеке вызовов.
* Если стек вызовов станет очень большим, он займет слишком много памяти.
</details>

<details>
  <summary>Быстрая сортировка</summary>

* Если вы реализуете алгоритм быстрой сортировки, выберите в качестве опорного случайный элемент. Среднее время выполнения быстрой сортировки составляет О(п log п)!
* Константы в «О-большом» иногда могут иметь значение . Именно по этой причине быстрая сортировка быстрее сортировки слиянием.
*  При сравнении простой сортировки с бинарной константа почти никогда роли не играет, потому что O(log п) слишком сильно превосходит О(п) по скорости при большом размере списка.
</details>

<details>
  <summary>Хеш-таблицы</summary>

* Хеш-таблица создается объединением хеш-функции с массивом.
* Коллизии нежелательны. Хеш функция должна свести количество коллизий к минимуму.
* Хеш-таблицы обеспечивают очень быстрое выполнение поиска, вставки и удаления.
* Хеш-таблицы хорошо подходят для моделирования отношений между объектами.
* Как только коэффициент заполнения превышает 0,7, пора изменять размер хеш-таблицы.
* Хеш-таблицы используются для кэширования данных (например, на веб-серверах ).
* Хеш-таблицы хорошо подходят для обнаружения дубликатов.
</details>

<details>
  <summary>Поиск в ширину</summary>

* Поиск в ширину позволяет определить, существует ли путь из А в В.
* Если путь существует, то поиск в ширину находит кратчайший путь.
* Если в вашей задаче требуется найти «кратчайшее Х», попробуйте смоделировать свою задачу графом и воспользуйтесь поиском в ширину для ее решения.
* В направленном графе есть стрелки, а отношения действуют в направлении стрелки (Рама-+ Адит означает «Рама должен Адиту» ).
* В ненаправленных графах стрелок нет, а отношение идет в обе сторон·ы (Росс - Рэйчел означает «Росс встречается с Рэйчел, а Рэйчел встречается с Россом».)
* Очереди относятся к категории FIFO («первым вошел, первым вышел»).
* Стек относится к категории LIFO («последним пришел, первым вышел»).
* Людей следует проверять в порядке их добавления в список поиска, поэтому список поиска должен быть оформлен в виде очереди, иначе найденный путь не будет кратчайшим.
* Позаботьтесь о том, чтобы уже проверенный человек не проверялся заново, иначе может возникнуть бесконечный цикл.
</details>

<details>
  <summary>Алгоритм Дейкстры</summary>

* Поиск в ширину вычисляет кратчайший путь в невзвешенном графе.
* Алгоритм Дейкстры вычисляет кратчайший путь во взвешенном графе.
* Алгоритм Дейкстры работает только в том случае, если все веса положительны.
* При наличии отрицательных весов используйте алгоритм БеллманаФорда.
</details>

<details>
  <summary>Жадные алгоритмы</summary>

* Жадные алгоритмы стремятся к локальной оптимизации в расчете на то, что в итоге будет достигнут глобальный оптимум.
* У NР-полных задач не существует известных быстрых решений.
* Если у вас имеется NР-полная задача, лучше всего воспользоваться приближенным алгоритмом.
* Жадные алгоритмы легко реализуются и быстро выполняются, поэтому из них получаются хорошие приближенные алгоритмы.
</details>

<details>
  <summary>Динамическое программирование</summary>

* Динамическое программирование применяется при оптимизации не которой характеристики.
* Динамическое программирование работает только в ситуациях, в кото рых задача может быть разбита на автономные под адачи.
* В каждом решении из области динамического программирования стро ится таблица.
* Значения ячеек таблицы обычно соответствуют оптимизируемой харак теристике.
* Каждая ячейка представляет подзадачу, поэтому вы должны подумать том, как разбить задачу на подзадачи.
* Не существует единой формулы для вычисления решений методом динамического программирования. 
</details>

<details>
  <summary>Алгоритм k ближайших соседей</summary>

* Алгоритм k ближайших соседей применяется для классификации и регрессии. В нем используется проверка k ближайших соседей.
* Классификация = распределение по категориям.
* Регрессия= прогнозирование результата (например, в виде числа).
* «Извлечением признаков» называется преобразование элемента (на пример, фрукта или пользователя) в список чисел, которые могут использоваться для сравнения.
* Качественный выбор признаков - важная часть успешного алгоритма k ближайших соседей. 
</details>